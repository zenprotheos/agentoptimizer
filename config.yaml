# AI Agent Framework Configuration
# Based on Pydantic AI ModelSettings: https://ai.pydantic.dev/api/settings/

# Template engine configuration
template_engine:
  name: jinja2
  autoescape: false           # Keep false to preserve Markdown formatting
  base_path: ./snippets       # Default directory for includes (relative paths)
  enable_async: true          # Support async rendering

# Default model settings
model_settings:
  # Model name - can be overridden per agent
  model: "openai/gpt-4o-mini"
  
  # Core generation parameters
  temperature: 0.7          # 0.0 = deterministic, higher = more creative
  max_tokens: 1024          # Maximum tokens to generate (reduced for cost control)
  
  # Advanced sampling (use either temperature OR top_p, not both)
  top_p: null               # Nucleus sampling, 0.1 = top 10% probability mass
  
  # Penalties to reduce repetition
  presence_penalty: null    # Penalize tokens that appeared in text so far
  frequency_penalty: null   # Penalize tokens based on frequency
  
  # Tool calling behavior
  parallel_tool_calls: true # Allow multiple tool calls in one response
  
  # Deterministic behavior
  seed: null                # Set for reproducible results
  
  # Stopping conditions
  stop_sequences: null      # List of strings that stop generation
  
  # Request timeout
  timeout: 30.0             # Timeout in seconds

# Agent defaults
agent_defaults:
  retries: 1                # Default number of retries
  output_retries: 1         # Max retries for output validation
  end_strategy: "early"     # "early" or "exhaustive" for tool handling
  
# Usage limits to prevent infinite loops and control costs
usage_limits:
  # Maximum number of requests per agent run (prevents infinite loops)
  request_limit: 100
  
  # Maximum tokens allowed in requests (null = no limit)
  request_tokens_limit: null
  
  # Maximum tokens allowed in responses (null = no limit)
  response_tokens_limit: null
  
  # Maximum total tokens (requests + responses) (null = no limit)
  total_tokens_limit: null
  
  # Whether to append tool usage statistics to tool responses so that agents know how many tool calls they have made and what the limits are
  show_usage_stats: true

# MCP Configuration paths
mcp_config:
  # Local project MCP config (higher priority)
  local_config_path: ".cursor/mcp.json"
  # Global system MCP config (lower priority) 
  global_config_path: "~/.cursor/mcp.json"
  # Whether to normalize server names to lowercase for matching
  case_insensitive_matching: true

# Logfire configuration
logfire:
  # Enable/disable Logfire logging
  enabled: true
  
  # Service name for Logfire (appears in the dashboard)
  service_name: "oneshot"
  
  # Log level (DEBUG, INFO, WARNING, ERROR)
  log_level: "INFO"
  
  # Whether to log tool calls and their results
  log_tool_calls: true
  
  # Whether to log token usage statistics
  log_usage: true
  
  # Whether to log agent execution details
  log_agent_execution: true
  
  # Whether to log individual LLM messages (can be verbose)
  log_llm_messages: true
  
  # Whether to enable automatic Pydantic AI instrumentation
  instrument_pydantic_ai: true
  
  # Whether to enable OpenAI instrumentation
  instrument_openai: true

# Framework settings
framework:
  agents_dir: "agents"      # Directory containing agent markdown files
  tools_dir: "tools"        # Directory containing tool Python scripts
  defer_model_check: false # Check model availability immediately
  
# Model restrictions for cost control
model_restrictions:
  # Block expensive models that charge per request
  blocked_models:
    - "openai/gpt-4o-mini-search-preview"
    - "openai/gpt-4-turbo-preview"
    - "openai/gpt-4-vision-preview"
    - "anthropic/claude-3.5-sonnet-latest"
  
  # Fallback model when blocked model is requested
  fallback_model: "openai/gpt-4o-mini" 